{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import ast\n",
    "import json\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from functools import partial\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Solution is kept trivial and highly inefficient on purpose as it's provided\n",
    "# purely as an example which should be straightforward to beat by anyone\n",
    "def convert_dataset(dataset):\n",
    "  examples = []\n",
    "  for blob in dataset['txData']:\n",
    "    txData = ast.literal_eval(blob)\n",
    "    examples.append([\n",
    "      int(txData['from'], 0) % (2 ** 30),\n",
    "      (int(txData['to'], 0) if txData['to'] is not None else 0) % (2 ** 30),\n",
    "      int(txData['gas'], 0),\n",
    "      int(txData['gasPrice'], 0),\n",
    "      (int(txData['input'][:10], 0) if txData['input'] != '0x' else 0) % (2 ** 30),\n",
    "      int(txData['nonce'], 0)\n",
    "    ])\n",
    "  return np.array(examples)\n",
    "\n",
    "def categorical_label(dataset):\n",
    "  txTrace = dataset['txTrace']\n",
    "  print(txTrace)\n",
    "  err_le = LabelEncoder()\n",
    "  err_label = err_le.fit_transform(txTrace['error'])\n",
    "  err_ohe = OneHotEncoder()\n",
    "  dataset['errorLabel'] = err_label\n",
    "\n",
    "  err_feature_arr = err_ohe.fit_transform(dataset[['errorLabel']]).toarray()\n",
    "  error = err_feature_arr.flatten()\n",
    "  print((err_feature_arr))\n",
    "  err_feature_label = list(err_le.classes_)\n",
    "  print(err_feature_label)\n",
    "  err_feature = pd.DataFrame(err_feature_arr.astype(int).astype(str))\n",
    "  err_feature['error'] = err_feature.stack().groupby(level=0).apply(''.join)\n",
    "  # err_feature['error'] = err_feature[err_feature_label].agg(''.join, axis=1)\n",
    "  print(err_feature['error'].dtype)\n",
    "  return err_feature['error']\n",
    "\n",
    "def feature_data(dataset):\n",
    "  examples = []\n",
    "\n",
    "  \n",
    "  for dat, trc in zip(dataset['txData'], dataset['txTrace']):  \n",
    "    data = ast.literal_eval(dat)\n",
    "    trace = ast.literal_eval(trc)\n",
    "    examples.append([\n",
    "      int(data['blockNumber'], 0),\n",
    "      int(data['from'], 0) % (2 ** 30),\n",
    "      (int(data['to'], 0) if data['to'] is not None else 0) % (2 ** 30),\n",
    "      int(data['gas'], 0),\n",
    "      ((int(trace['gasUsed'], 0) + 21000) *int(data['gasPrice'], 0)),\n",
    "      (int(data['input'][:10], 0) if data['input'] != '0x' else 0) % (2 ** 30),\n",
    "      int(data['nonce'], 0)\n",
    "    ])\n",
    "  return np.array(examples)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "test =  pd.read_csv('test.csv', nrows=22)\n",
    "\n",
    "# test = pd.concat([test.drop(['txData', 'txTrace'], axis=1), pd.json_normalize(test['txData']), pd.json_normalize(test['txTrace'])], axis=1)\n",
    "# test.columns = ['txHash', 'blockNumber', 'from', 'to', 'gas', 'gasPrice', 'input',\n",
    "#        'nonce', 'publicKey', 'value', 'type', 'from', 'to', 'value', 'gas1',\n",
    "#        'input', 'output', 'gasUsed', 'blockNumber', 'transactionHash', 'calls',\n",
    "#        'error']\n",
    "\n",
    "# print(np.unique(test['error'].astype(str)))\n",
    "# print(str(test['calls'].iloc[20] ) + str(int(test['gasUsed'].iloc[20], 0) ) + '  nonce  ' + str(int(test['nonce'].iloc[20], 0)) + '  gasPrice  ' + str(int(test['gas'].iloc[20], 0)) + ' ' + str((int(test['gasUsed'].iloc[20], 0) + 21000 )*int(test['gasPrice'].iloc[20], 0)/10**18) )\n",
    "# print(test['gasUsed'].astype(str).apply(int, base=0) if test['gasUsed'].astype(str) != 'nan' else 0)\n",
    "print(feature_data(test))\n",
    "# err_le = LabelEncoder()\n",
    "# err_ohe = OneHotEncoder()\n",
    "\n",
    "# err_label = err_le.fit_transform(test['error'])\n",
    "# test['Error_label'] = err_label\n",
    "\n",
    "# err_feature_arr = err_ohe.fit_transform(test[['Error_label']]).toarray()\n",
    "# err_feature_label = list(err_le.classes_)\n",
    "# err_feature = pd.DataFrame(err_feature_arr, columns=err_feature_label)\n",
    "\n",
    "# feature = pd.concat([test, err_feature], axis=1)\n",
    "# print(feature.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0     {'type': 'CALL', 'from': '0xa42830ee059c77caf8...\n",
      "1     {'type': 'CALL', 'from': '0x04296f2966f44fe26d...\n",
      "2     {'type': 'CALL', 'from': '0x5988e6182834aa9d02...\n",
      "3     {'type': 'CALL', 'from': '0x15f09a042d2e3c05c7...\n",
      "4     {'type': 'CALL', 'from': '0xfde69621578dbbaafb...\n",
      "5     {'type': 'CALL', 'from': '0x90db5ec42748fba62f...\n",
      "6     {'type': 'CALL', 'from': '0x7879c1ee409392c050...\n",
      "7     {'type': 'CALL', 'from': '0x00192fb10df37c9fb2...\n",
      "8     {'type': 'CALL', 'from': '0x00192fb10df37c9fb2...\n",
      "9     {'type': 'CALL', 'from': '0x0000a0756737268a63...\n",
      "10    {'type': 'CALL', 'from': '0x46f43535c50edfc78c...\n",
      "11    {'type': 'CALL', 'from': '0x0d0b715a705c88adf7...\n",
      "12    {'type': 'CALL', 'from': '0x75e89d5979e4f6fba9...\n",
      "13    {'type': 'CALL', 'from': '0xd24400ae8bfebb18ca...\n",
      "14    {'type': 'CALL', 'from': '0x62af1537f9b2c9e6d9...\n",
      "15    {'type': 'CALL', 'from': '0xd60dfa5ce2bdbe9ad5...\n",
      "16    {'type': 'CALL', 'from': '0x494f694a03f8c7198a...\n",
      "17    {'type': 'CALL', 'from': '0x945731c3791ed8a21c...\n",
      "18    {'type': 'CALL', 'from': '0xae42eb16ecd6df1e40...\n",
      "19    {'type': 'CALL', 'from': '0x3a723e58c4808dde45...\n",
      "20    {'type': 'CALL', 'from': '0xea674fdde714fd979d...\n",
      "21    {'type': 'CALL', 'from': '0x1d18e9bdd58f4b11d3...\n",
      "Name: txTrace, dtype: object\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'error'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19351/576097508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# print(str(test['calls'].iloc[20] ) + str(int(test['gasUsed'].iloc[20], 0) ) + '  nonce  ' + str(int(test['nonce'].iloc[20], 0)) + '  gasPrice  ' + str(int(test['gas'].iloc[20], 0)) + ' ' + str((int(test['gasUsed'].iloc[20], 0) + 21000 )*int(test['gasPrice'].iloc[20], 0)/10**18) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print(test['gasUsed'].astype(str).apply(int, base=0) if test['gasUsed'].astype(str) != 'nan' else 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# err_le = LabelEncoder()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# err_ohe = OneHotEncoder()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19351/2533405622.py\u001b[0m in \u001b[0;36mfeature_data\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0merr_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0merr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxTrace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0merr_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errorLabel'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Projects/MachineLearnECT/env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Projects/MachineLearnECT/env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Projects/MachineLearnECT/env/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'error'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "testFeatures = feature_data(test)\n",
    " \n",
    "binaryModel = xgb.XGBClassifier(n_estimators=50)\n",
    "binaryModel.fit(feature_data(train), train['Label0'])\n",
    "print(binaryModel.feature_importances_)\n",
    "binaryPredictions = binaryModel.predict_proba(testFeatures)[:, 1]\n",
    " \n",
    "regressionModel = xgb.XGBRegressor(n_estimators=50)\n",
    "regressionModel.fit(\n",
    "  feature_data(train[train['Label0'] == True]),\n",
    "  train[train['Label0'] == True]['Label1']\n",
    ")\n",
    "print(regressionModel.feature_importances_)\n",
    "regressionPredictions = regressionModel.predict(testFeatures)\n",
    " \n",
    "submission = csv.writer(open('submission.csv', 'w', encoding='UTF8'))\n",
    "for x, y in zip(binaryPredictions, regressionPredictions):\n",
    "  submission.writerow([x, y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = pd.read_csv('train.csv', converters={'txData': ast.literal_eval, 'txTrace': ast.literal_eval})\n",
    "test = pd.read_csv('test.csv',converters={'txData': ast.literal_eval, 'txTrace': ast.literal_eval})\n",
    "testFeatures = feature_data(test)\n",
    "print(\"start\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_data(train), train['Label0'], test_size=0.2) \n",
    "binaryModel = xgb.XGBClassifier(n_estimators=50)\n",
    "binaryModel.fit(X_train, y_train)\n",
    "print(binaryModel.feature_importances_)\n",
    "binaryPredictions = binaryModel.predict_proba(testFeatures)[:, 1]\n",
    " \n",
    "regressionModel = xgb.XGBRegressor(n_estimators=50)\n",
    "regressionModel.fit(\n",
    "  feature_data(train[train['Label0'] == True]),\n",
    "  train[train['Label0'] == True]['Label1']\n",
    ")\n",
    "print(regressionModel.feature_importances_)\n",
    "regressionPredictions = regressionModel.predict(testFeatures)\n",
    " \n",
    "predictions = binaryModel.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('accuracy %.2f', accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "2dd582f4d494157b7b25c87d8749050f5acfadec8e6aca5fd38f0bbbb455f280"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}